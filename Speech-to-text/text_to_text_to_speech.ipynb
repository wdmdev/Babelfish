{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'translate'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# !python3 -m pip install gTTS setuptools filelock torch translate transformers librosa pydub\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[39m## Text-to-text translation\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtranslate\u001b[39;00m \u001b[39mimport\u001b[39;00m Translator\n\u001b[1;32m      6\u001b[0m \u001b[39m## Text-to-speech \u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgtts\u001b[39;00m \u001b[39mimport\u001b[39;00m gTTS\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'translate'"
     ]
    }
   ],
   "source": [
    "## Text-to-text translation\n",
    "from translate import Translator\n",
    "\n",
    "## Text-to-speech \n",
    "from gtts import gTTS\n",
    "from pydub import AudioSegment\n",
    "\n",
    "# Danish speech to text\n",
    "import os\n",
    "import torch\n",
    "import librosa\n",
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load audio WAV file with Danish speech and transcribe into text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "og det er jo i sidste instans målet\n"
     ]
    }
   ],
   "source": [
    "def transcribe_danish_audio(audio_file_path, sampling_rate=16000):\n",
    "    # load model and tokenizer\n",
    "    processor = Wav2Vec2Processor.from_pretrained(\n",
    "        \"chcaa/xls-r-300m-danish-nst-cv9\")\n",
    "    model = Wav2Vec2ForCTC.from_pretrained(\n",
    "        \"chcaa/xls-r-300m-danish-nst-cv9\")\n",
    "\n",
    "    wave, sr = librosa.load(audio_file_path, sr=sampling_rate)\n",
    "\n",
    "    # tokenize\n",
    "    input_values = processor(wave, return_tensors=\"pt\", padding=\"longest\", sampling_rate=sampling_rate).input_values  # Batch size 1\n",
    "\n",
    "    # retrieve logits\n",
    "    logits = model(input_values).logits\n",
    "\n",
    "    # take argmax and decode\n",
    "    predicted_ids = torch.argmax(logits, dim=-1)\n",
    "    transcription = processor.batch_decode(predicted_ids)\n",
    "    return ' '.join(transcription)\n",
    "\n",
    "\n",
    "audio_file_path = 'Speech-to-text/common_voice_da_27769309.wav'\n",
    "danish_transcription = transcribe_danish_audio(audio_file_path)\n",
    "print(danish_transcription)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load .txt file with danish text, translate to english text using API, save as .txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_file(source_file_path, target_file_path='translated_text.txt', source_lang='da', target_lang='en'):\n",
    "    \n",
    "    ## Read the text file\n",
    "    source_text = open(source_file_path, 'r').read().lower()\n",
    "\n",
    "    ## Define the translator\n",
    "    file_translator = Translator(from_lang=source_lang, to_lang=target_lang)\n",
    "\n",
    "    ## Translate the text\n",
    "    translation = file_translator.translate(source_text)\n",
    "\n",
    "    ## Save the translation\n",
    "    with open(target_file_path, 'w') as f:\n",
    "        f.write(translation)\n",
    "\n",
    "    return translation\n",
    "\n",
    "# trans = translate_file(source_file_path='danish_text1.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load .txt file with english text, convert to audio using API, save as .wav file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TTS_file(source_text_file_path, language='en'):\n",
    "    ## Read translated text file  ## Read the text file\n",
    "    translated_text = open(source_text_file_path, 'r').read().lower()\n",
    "    # print(translated_text)\n",
    "\n",
    "    ## Read aloud translated text using Google Text-to-Speech\n",
    "    TTS_speech = gTTS(text=translated_text, lang='en', slow=False)\n",
    "    TTS_speech.save(\"TTS_speech.mp3\")\n",
    "\n",
    "    ## Convert mp3 to wav, as gTTS only supports mp3\n",
    "    sound = AudioSegment.from_mp3(\"TTS_speech.mp3\")\n",
    "    sound.export(\"TTS_speech.wav\", format=\"wav\")\n",
    "    \n",
    "    return\n",
    "\n",
    "# TTS_file(source_text_file_path='translated_text.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load .txt file with danish text, translate to english text using API, save as .txt file, then load .txt file with english text, convert to audio using API, save as .wav file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def translate_TTS_file(src_file_path, tgt_file_path='translated_text.txt', src_lang='da', tgt_lang='en'):\n",
    "    \n",
    "#     translation = translate_file(source_file_path=src_file_path, target_file_path=tgt_file_path, source_lang=src_lang, target_lang=tgt_lang)\n",
    "#     print(translation)\n",
    "#     TTS_file(source_text_file_path=tgt_file_path, language=tgt_lang)\n",
    "\n",
    "#     return\n",
    "\n",
    "# translate_TTS_file(src_file_path='danish_text1.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source text:  og det er jo i sidste instans målet\n",
      "Translated text:  Surely this must be the ultimate goal.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work1/s183921/StarGANv2-VC-emotion/Speech-to-text/env/lib/python3.9/site-packages/pydub/utils.py:198: RuntimeWarning: Couldn't find ffprobe or avprobe - defaulting to ffprobe, but may not work\n",
      "  warn(\"Couldn't find ffprobe or avprobe - defaulting to ffprobe, but may not work\", RuntimeWarning)\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'ffprobe'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [24], line 24\u001b[0m\n\u001b[1;32m     20\u001b[0m     sound\u001b[39m.\u001b[39mexport(tgt_file_path, \u001b[39mformat\u001b[39m\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mwav\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     22\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m translate_TTS_file(source_text\u001b[39m=\u001b[39;49mdanish_transcription, print_bol\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "Cell \u001b[0;32mIn [24], line 19\u001b[0m, in \u001b[0;36mtranslate_TTS_file\u001b[0;34m(source_text, tgt_file_path, src_lang, tgt_lang, print_bol)\u001b[0m\n\u001b[1;32m     16\u001b[0m TTS_speech\u001b[39m.\u001b[39msave(\u001b[39m'\u001b[39m\u001b[39mTTS_speech.mp3\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     18\u001b[0m \u001b[39m## Convert mp3 to wav, as gTTS only supports mp3\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m sound \u001b[39m=\u001b[39m AudioSegment\u001b[39m.\u001b[39;49mfrom_mp3(\u001b[39m'\u001b[39;49m\u001b[39mTTS_speech.mp3\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     20\u001b[0m sound\u001b[39m.\u001b[39mexport(tgt_file_path, \u001b[39mformat\u001b[39m\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mwav\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     22\u001b[0m \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[0;32m/work1/s183921/StarGANv2-VC-emotion/Speech-to-text/env/lib/python3.9/site-packages/pydub/audio_segment.py:796\u001b[0m, in \u001b[0;36mAudioSegment.from_mp3\u001b[0;34m(cls, file, parameters)\u001b[0m\n\u001b[1;32m    794\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    795\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfrom_mp3\u001b[39m(\u001b[39mcls\u001b[39m, file, parameters\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 796\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49mfrom_file(file, \u001b[39m'\u001b[39;49m\u001b[39mmp3\u001b[39;49m\u001b[39m'\u001b[39;49m, parameters\u001b[39m=\u001b[39;49mparameters)\n",
      "File \u001b[0;32m/work1/s183921/StarGANv2-VC-emotion/Speech-to-text/env/lib/python3.9/site-packages/pydub/audio_segment.py:728\u001b[0m, in \u001b[0;36mAudioSegment.from_file\u001b[0;34m(cls, file, format, codec, parameters, start_second, duration, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m     info \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    727\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 728\u001b[0m     info \u001b[39m=\u001b[39m mediainfo_json(orig_file, read_ahead_limit\u001b[39m=\u001b[39;49mread_ahead_limit)\n\u001b[1;32m    729\u001b[0m \u001b[39mif\u001b[39;00m info:\n\u001b[1;32m    730\u001b[0m     audio_streams \u001b[39m=\u001b[39m [x \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m info[\u001b[39m'\u001b[39m\u001b[39mstreams\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m    731\u001b[0m                      \u001b[39mif\u001b[39;00m x[\u001b[39m'\u001b[39m\u001b[39mcodec_type\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39maudio\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[0;32m/work1/s183921/StarGANv2-VC-emotion/Speech-to-text/env/lib/python3.9/site-packages/pydub/utils.py:274\u001b[0m, in \u001b[0;36mmediainfo_json\u001b[0;34m(filepath, read_ahead_limit)\u001b[0m\n\u001b[1;32m    271\u001b[0m         file\u001b[39m.\u001b[39mclose()\n\u001b[1;32m    273\u001b[0m command \u001b[39m=\u001b[39m [prober, \u001b[39m'\u001b[39m\u001b[39m-of\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mjson\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m+\u001b[39m command_args\n\u001b[0;32m--> 274\u001b[0m res \u001b[39m=\u001b[39m Popen(command, stdin\u001b[39m=\u001b[39;49mstdin_parameter, stdout\u001b[39m=\u001b[39;49mPIPE, stderr\u001b[39m=\u001b[39;49mPIPE)\n\u001b[1;32m    275\u001b[0m output, stderr \u001b[39m=\u001b[39m res\u001b[39m.\u001b[39mcommunicate(\u001b[39minput\u001b[39m\u001b[39m=\u001b[39mstdin_data)\n\u001b[1;32m    276\u001b[0m output \u001b[39m=\u001b[39m output\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m/appl/python/3.9.11/lib/python3.9/subprocess.py:951\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask)\u001b[0m\n\u001b[1;32m    947\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtext_mode:\n\u001b[1;32m    948\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstderr \u001b[39m=\u001b[39m io\u001b[39m.\u001b[39mTextIOWrapper(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstderr,\n\u001b[1;32m    949\u001b[0m                     encoding\u001b[39m=\u001b[39mencoding, errors\u001b[39m=\u001b[39merrors)\n\u001b[0;32m--> 951\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_execute_child(args, executable, preexec_fn, close_fds,\n\u001b[1;32m    952\u001b[0m                         pass_fds, cwd, env,\n\u001b[1;32m    953\u001b[0m                         startupinfo, creationflags, shell,\n\u001b[1;32m    954\u001b[0m                         p2cread, p2cwrite,\n\u001b[1;32m    955\u001b[0m                         c2pread, c2pwrite,\n\u001b[1;32m    956\u001b[0m                         errread, errwrite,\n\u001b[1;32m    957\u001b[0m                         restore_signals,\n\u001b[1;32m    958\u001b[0m                         gid, gids, uid, umask,\n\u001b[1;32m    959\u001b[0m                         start_new_session)\n\u001b[1;32m    960\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m    961\u001b[0m     \u001b[39m# Cleanup if the child failed starting.\u001b[39;00m\n\u001b[1;32m    962\u001b[0m     \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m \u001b[39mfilter\u001b[39m(\u001b[39mNone\u001b[39;00m, (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstdin, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstdout, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstderr)):\n",
      "File \u001b[0;32m/appl/python/3.9.11/lib/python3.9/subprocess.py:1821\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, gid, gids, uid, umask, start_new_session)\u001b[0m\n\u001b[1;32m   1819\u001b[0m     \u001b[39mif\u001b[39;00m errno_num \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1820\u001b[0m         err_msg \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mstrerror(errno_num)\n\u001b[0;32m-> 1821\u001b[0m     \u001b[39mraise\u001b[39;00m child_exception_type(errno_num, err_msg, err_filename)\n\u001b[1;32m   1822\u001b[0m \u001b[39mraise\u001b[39;00m child_exception_type(err_msg)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'ffprobe'"
     ]
    }
   ],
   "source": [
    "def translate_TTS_file(source_text, tgt_file_path='TTS_speech.wav', src_lang='da', tgt_lang='en', print_bol=False):\n",
    "\n",
    "    ## Define the translator\n",
    "    file_translator = Translator(from_lang=src_lang, to_lang=tgt_lang)\n",
    "\n",
    "    ## Print source and translated text if specified\n",
    "    if print_bol:\n",
    "        print('Source text: ', source_text)\n",
    "        print('Translated text: ', file_translator.translate(source_text))\n",
    "\n",
    "    ## Translate the text\n",
    "    translated_text = file_translator.translate(source_text)\n",
    "\n",
    "    ## Read aloud translated text using Google Text-to-Speech\n",
    "    TTS_speech = gTTS(text=translated_text, lang=tgt_lang, slow=False)\n",
    "    TTS_speech.save('TTS_speech.mp3')\n",
    "\n",
    "    ## Convert mp3 to wav, as gTTS only supports mp3\n",
    "    sound = AudioSegment.from_mp3('TTS_speech.mp3')\n",
    "    sound.export(tgt_file_path, format=\"wav\")\n",
    "    \n",
    "    return\n",
    "\n",
    "translate_TTS_file(source_text=danish_transcription, print_bol=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
